{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Multiple Sclerosis Classifier\n",
    "\n",
    "This notebook contains a simple classifier for multiple sclerosis (MS) based on gene expression data. The goal of this project is to learn how to write a simple classifier for healthy and unhealthy patients.\n",
    "\n",
    "The data is from a study comparing gene expression in peripheral blood samples between healthy human individuals and patients with relapsing-remitting multiple sclerosis (RRMS). The data was generated using RNA sequencing (RNA-Seq) to identify differences in mRNA levels between the two groups.\n",
    "\n",
    "If you prefer you can use alternative datasets, classifying different diseases. Data can be acquired [here](https://www.ebi.ac.uk/gxa/experiments?experimentType=%22Differential%22&species=homo+sapiens). \n",
    "Choose datasets with at least two experimental factors. \n",
    "The default dataset (MS) was from [this](https://www.ebi.ac.uk/gxa/experiments/E-GEOD-66573/Results) link.\n",
    "In case you are unsure how to handle different datasets, an alternative [dataset](https://www.ebi.ac.uk/gxa/experiments/E-ENAD-46/Results) is included as an example and can be loaded by changing `DATASET = lung` further below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## Data Files\n",
    "\n",
    "The data is located in the `data/` folder and consists of two datasets: Multiple Sclerosis (MS) and Lung.\n",
    "\n",
    "### Multiple Sclerosis (MS)\n",
    "\n",
    "The MS data is located in the `data/ms/` folder and consists of the following files:\n",
    "\n",
    "*   `data/ms/raw-counts.tsv`: This file contains the raw gene counts for each sample. The rows represent genes and the columns represent samples.\n",
    "*   `data/ms/experiment-design.tsv`: This file describes the samples, indicating which ones are from healthy controls and which are from RRMS patients, along with other relevant metadata.\n",
    "*   `data/ms/query-results.tsv`: This file contains the query results from the Expression Atlas database.\n",
    "\n",
    "### Lung\n",
    "\n",
    "The Lung data is located in the `data/lung/` folder and consists of the following files:\n",
    "\n",
    "*   `data/lung/raw-counts.tsv`: This file contains the raw gene counts for each sample. The rows represent genes and the columns represent samples.\n",
    "*   `data/lung/experiment-design.tsv`: This file describes the samples and their metadata.\n",
    "*   `data/lung/query-results.tsv`: This file contains the query results from the Expression Atlas database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e6",
   "metadata": {},
   "source": [
    "### Your Tasks\n",
    "\n",
    "Your main task is to improve the classifier by selecting better features. This involves the following steps:\n",
    "\n",
    "1.  **Familiarize yourself with the covariance matrix:** The covariance matrix is a powerful tool for understanding the relationships between features. The current version of this notebook generates a covariance matrix for the first 5 genes.\n",
    "2.  **Normalization:** The data is normalized before calculating the covariance matrix. Why is this important? What would happen if you didn't normalize the data?\n",
    "3.  **Feature Selection:** The current version of the notebook only uses the first 5 genes as features. You should experiment with different sets of features to see if you can improve the accuracy of the classifier. You can use the information from the `query results` dataframe to select genes that are differentially expressed between the two groups.\n",
    "4.  **Interpret the covariance matrix:** What does it mean if a value in the covariance matrix is close to 0? What does it mean if it is close to 1? How can you use this information to select features?\n",
    "5.  **Implement k-fold cross validation:** Since we have limited data (only 14 samples total), a single train/test split may not give us a reliable estimate of model performance. Implement k-fold cross validation to get a more robust evaluation of your classifier. Consider what value of k would be appropriate given our small dataset size. Compare the results from k-fold cross validation with the simple train/test split approach currently used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f05e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\46705\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Ensure that packages are installed\n",
    "!pip install pandas scikit-learn matplotlib numpy\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "### Raw Counts\n",
    "\n",
    "This file contains the raw gene counts for each sample. The rows represent genes and the columns represent samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_markdown_cell",
   "metadata": {},
   "source": [
    "### Select the dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "new_code_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"ms\" # or \"lung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b18b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = f\"data/{DATASET}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53869909",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/ms/raw-counts.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_raw_counts \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATA_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/raw-counts.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_raw_counts\n\u001b[0;32m      3\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_raw_counts\u001b[38;5;241m.\u001b[39mloc[df_raw_counts\u001b[38;5;241m.\u001b[39mnunique(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\46705\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\46705\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\46705\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\46705\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\46705\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ms/raw-counts.tsv'"
     ]
    }
   ],
   "source": [
    "df_raw_counts = pd.read_csv(f\"{DATA_DIR}/raw-counts.tsv\", sep=\"\\t\", index_col=0)\n",
    "df_raw_counts\n",
    "df_filtered = df_raw_counts.loc[df_raw_counts.nunique(axis=1) > 1]\n",
    "\n",
    "print(f\"Original genes: {df_raw_counts.shape[0]}\")\n",
    "print(f\"Filtered genes: {df_filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "### Experiment Design\n",
    "\n",
    "This file describes the samples, indicating which ones are from healthy controls and which are from RRMS patients, along with other relevant metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment_design = pd.read_csv(f\"{DATA_DIR}/experiment-design.tsv\", sep=\"\\t\", index_col=0)\n",
    "df_experiment_design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6g7h8i9",
   "metadata": {},
   "source": [
    "### Query Results\n",
    "\n",
    "This file contains the query results from the Expression Atlas database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_results = pd.read_csv(f\"{DATA_DIR}/query-results.tsv\", sep=\"\\t\", index_col=0)\n",
    "df_query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g7h8i9j0",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Before we can train a classifier, we need to prepare the data. This involves selecting features and labels from the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49036aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_of_patient(df, patient_id):\n",
    "    \"\"\"\n",
    "    Get the raw gene counts of a specific patient from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing patient data.\n",
    "    patient_id (str): ID of the patient to retrieve features for. You can find the IDs in the first column of the analytics dataframe.\n",
    "    \n",
    "    Returns:\n",
    "    pd.Series: Features of the specified patient.\n",
    "    \"\"\"\n",
    "    return df[patient_id][:5].to_list() # TODO: Select features smartly, not just the first 5 (genes)\n",
    "\n",
    "get_features_of_patient(df_raw_counts, \"SRR1839791\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df_raw_counts, df_experiment_design): \n",
    "    \"\"\"\n",
    "    Get the entire dataset of features and labels.\n",
    "    \n",
    "    Parameters:\n",
    "    df_raw_counts (pd.DataFrame): DataFrame containing raw gene counts.\n",
    "    df_experiment_design (pd.DataFrame): DataFrame containing experiment design data.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Features and labels for the dataset.\n",
    "    \"\"\"\n",
    "    patient_ids = df_experiment_design.index.to_list()\n",
    "    features = [get_features_of_patient(df_raw_counts, patient_id) for patient_id in patient_ids]\n",
    "    labels = df_experiment_design[\"Sample Characteristic[disease]\"].to_list()\n",
    "    unique_labels = list(set(labels))\n",
    "    labels = [unique_labels.index(label) for label in labels] # Convert labels to numbers\n",
    "    return features, labels\n",
    "\n",
    "features, labels = get_dataset(df_raw_counts, df_experiment_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_genes(df, samples, labels, n_genes=50):\n",
    "    healthy = labels == 0\n",
    "    disease = labels == 1\n",
    "    \n",
    "    mean_h = df.loc[:, samples[healthy]].mean(axis=1)\n",
    "    mean_d = df.loc[:, samples[disease]].mean(axis=1)\n",
    "    \n",
    "    return (mean_d - mean_h).abs().nlargest(n_genes).index\n",
    "\n",
    "\n",
    "def build_dataset(df, genes, samples):\n",
    "    return df.loc[genes, samples].T.values\n",
    "\n",
    "\n",
    "def scale_and_pca(X_train, X_test, n_components=4):\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(X_train), pca.transform(X_test), pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h8i9j0k1",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "We split the data into a training set and a testing set. The training set is used to train the classifier, and the testing set is used to evaluate its performance. The main bottleneck we have with that project is the lack of enough data. In fact, we have 14 cases in total with 8 and 6 cases respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864af4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.5, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "### Train the Classifier\n",
    "\n",
    "We use a simple Decision Tree Classifier to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1759f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=2)\n",
    "classifier = classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j0k1l2m3",
   "metadata": {},
   "source": [
    "### Evaluate the Classifier\n",
    "\n",
    "We use the accuracy score to evaluate the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_labels = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7498d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filtered.T.values\n",
    "y = (df_experiment_design[\"Sample Characteristic[disease]\"] != \"normal\").astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Baseline accuracy:\", accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covariance_matrix_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [10, 20, 30, 50, 80, 100]\n",
    "acc_no_pca, acc_pca = [], []\n",
    "\n",
    "for k in k_values:\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    Xk = selector.fit_transform(X_train, y_train)\n",
    "    Xk_test = selector.transform(X_test)\n",
    "    \n",
    "    Xk, Xk_test, _ = scale_and_pca(Xk, Xk_test, n_components=4)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    clf.fit(Xk, y_train)\n",
    "    acc_pca.append(accuracy_score(y_test, clf.predict(Xk_test)))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(k_values, acc_pca, marker=\"o\")\n",
    "plt.xlabel(\"Number of Selected Genes\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Top-k Gene Selection\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_gene_feature(df_raw_counts, df_experiment_design, gene): \n",
    "    \"\"\"\n",
    "    Get the single gene feature for all patients in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df_raw_counts (pd.DataFrame): DataFrame containing raw gene counts.\n",
    "    df_experiment_design (pd.DataFrame): DataFrame containing experiment design data.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Features and labels for the dataset.\n",
    "    \"\"\"\n",
    "    patient_ids = df_experiment_design.index.to_list()\n",
    "\n",
    "    gene_index = df_raw_counts.index.get_loc(gene)\n",
    "\n",
    "    features = [df_raw_counts[patient_id][gene_index:gene_index + 1].to_list() for patient_id in patient_ids]\n",
    "    labels = df_experiment_design[\"Sample Characteristic[disease]\"].to_list()\n",
    "    unique_labels = list(set(labels))\n",
    "    labels = [unique_labels.index(label) for label in labels] # Convert labels to numbers\n",
    "    return features, labels\n",
    "\n",
    "single_feature, labels = get_single_gene_feature(df_raw_counts, df_experiment_design, \"ENSG00000250696\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"Logistic Regression\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"KNN (k=3)\": KNeighborsClassifier(3),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\")\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = {}\n",
    "\n",
    "samples = df_experiment_design.index.to_numpy()\n",
    "labels = y.to_numpy()\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = []\n",
    "    for train_idx, test_idx in kf.split(samples):\n",
    "        genes = select_top_genes(df_raw_counts, samples[train_idx], labels[train_idx])\n",
    "        X_train = build_dataset(df_raw_counts, genes, samples[train_idx])\n",
    "        X_test = build_dataset(df_raw_counts, genes, samples[test_idx])\n",
    "        \n",
    "        X_train, X_test, _ = scale_and_pca(X_train, X_test)\n",
    "        model.fit(X_train, labels[train_idx])\n",
    "        scores.append(accuracy_score(labels[test_idx], model.predict(X_test)))\n",
    "    \n",
    "    results[name] = (np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3318674",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(results.keys())\n",
    "means = [results[n][0] for n in names]\n",
    "stds = [results[n][1] for n in names]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(names, means, yerr=stds, capsize=5)\n",
    "plt.ylabel(\"Mean Accuracy\")\n",
    "plt.title(\"Model Comparison (7-Fold CV)\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(axis=\"y\", alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = select_top_genes(df_raw_counts, samples, labels)\n",
    "X = build_dataset(df_raw_counts, genes, samples)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "pairs = [(0,1), (0,2), (1,2)]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i, (a,b) in enumerate(pairs):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    for lab, color in zip([0,1], [\"blue\",\"red\"]):\n",
    "        plt.scatter(X_pca[labels==lab,a], X_pca[labels==lab,b], color=color, label=str(lab), alpha=0.7)\n",
    "    plt.xlabel(f\"PC{a+1}\")\n",
    "    plt.ylabel(f\"PC{b+1}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(X, rowvar=False)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cov, cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Covariance Matrix (Top 50 Genes)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7899922",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = genes[:10]\n",
    "expr = np.log1p(df_raw_counts.loc[top10, samples].T)\n",
    "expr[\"Disease\"] = df_experiment_design[\"Sample Characteristic[disease]\"].values\n",
    "\n",
    "expr_melt = expr.melt(id_vars=\"Disease\", var_name=\"Gene\", value_name=\"Expression\")\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.stripplot(data=expr_melt, x=\"Gene\", y=\"Expression\", hue=\"Disease\", jitter=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 10 Differentially Expressed Genes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a15398",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [10, 20, 30, 50, 100]\n",
    "acc_no_pca, acc_pca = [], []\n",
    "\n",
    "for k in k_values:\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    Xk = selector.fit_transform(X_train, y_train)\n",
    "    Xk_test = selector.transform(X_test)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    Xk = scaler.fit_transform(Xk)\n",
    "    Xk_test = scaler.transform(Xk_test)\n",
    "\n",
    "    # No PCA\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(Xk, y_train)\n",
    "    acc_no_pca.append(accuracy_score(y_test, clf.predict(Xk_test)))\n",
    "\n",
    "    # With PCA\n",
    "    pca = PCA(n_components=4)\n",
    "    clf.fit(pca.fit_transform(Xk), y_train)\n",
    "    acc_pca.append(accuracy_score(y_test, clf.predict(pca.transform(Xk_test))))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(k_values, acc_no_pca, marker='o', label=\"No PCA\")\n",
    "plt.plot(k_values, acc_pca, marker='s', label=\"With PCA\")\n",
    "plt.xlabel(\"Top-k Genes\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"ANOVA Feature Selection: PCA vs No PCA\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ea007",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits = [5, 6, 7, 8, 9]\n",
    "means, stds = [], []\n",
    "\n",
    "for k in cv_splits:\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(samples):\n",
    "        genes = select_top_genes(df_raw_counts, samples[train_idx], labels[train_idx])\n",
    "        X_train = build_dataset(df_raw_counts, genes, samples[train_idx])\n",
    "        X_test = build_dataset(df_raw_counts, genes, samples[test_idx])\n",
    "\n",
    "        X_train, X_test, _ = scale_and_pca(X_train, X_test)\n",
    "        model = SVC(kernel=\"linear\")\n",
    "        model.fit(X_train, labels[train_idx])\n",
    "        scores.append(accuracy_score(labels[test_idx], model.predict(X_test)))\n",
    "\n",
    "    means.append(np.mean(scores))\n",
    "    stds.append(np.std(scores))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar([f\"{k}-Fold\" for k in cv_splits], means, yerr=stds, capsize=5)\n",
    "plt.ylabel(\"Mean Accuracy\")\n",
    "plt.title(\"Effect of CV Splits on Model Stability\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(axis=\"y\", alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"linear\")\n",
    "svm.fit(X_pca, labels)\n",
    "\n",
    "pc_importance = np.abs(svm.coef_[0])\n",
    "explained = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(range(1, len(explained)+1), explained, alpha=0.6, label=\"Explained Variance\")\n",
    "plt.plot(range(1, len(pc_importance)+1), pc_importance, marker='o', color='red', label=\"PC Importance\")\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.title(\"Explained Variance vs PC Importance\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
